{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-python\n",
    "#!apt-get update ##[edited]\n",
    "#!apt-get install ffmpeg libsm6 libxext6  -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import s3fs\n",
    "import numpy as np\n",
    "import boto3\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sxm-ecomm-sagemaker-dev/images/21.331533,-157.865814_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/27.780159,-82.638729_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/28.541808,-81.371378_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/28.782888,-97.045563_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/29.617713,-95.564214_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/30.742342,-99.225417_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/31.782211,-97.576846_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/32.012106,-90.357557_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/32.593073,-85.488610_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/32.621311,-93.268366_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/32.747997,-97.081101_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/32.768546,-117.148398_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/32.776300,-96.806562_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/32.781604,-97.388521_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/32.876899,-117.186056_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/33.430566,-111.938559_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/33.446081,-112.072305_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/33.756855,-84.386073_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/33.836291,-118.328960_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/33.858246,-118.082556_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/33.946706,-83.383487_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/34.042803,-118.219286_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/34.075591,-117.719565_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/34.077039,-118.046992_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/34.221697,-118.467373_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/34.311032,-92.413717_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/34.556566,-117.288937_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/35.042763,-110.699142_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/35.218759,-97.422209_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/35.270870,-111.544006_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/35.290586,-80.766020_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/35.404598,-94.460398_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/35.467226,-93.831410_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/35.484282,-120.665052_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/35.504615,-82.523931_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/35.507775,-87.226297_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/35.981815,-87.317253_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/36.161239,-86.783973_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/36.319750,-86.599870_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/36.461764,-94.302287_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/36.642210,-93.204353_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/36.808486,-119.874246_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/36.889373,-89.543597_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/37.228000,-80.413300_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/37.315876,-122.031860_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/37.568253,-122.026146_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/37.570248,-90.286181_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/37.673163,-122.085555_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/37.754088,-100.044436_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/37.761433,-122.477325_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/37.771274,-122.415826_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/37.810012,-122.245290_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/38.306587,-90.531544_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/38.347330,-122.710127_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/38.452114,-122.750846_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/38.542992,-90.192497_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/38.567398,-90.495452_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/38.664221,-121.272608_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/38.685054,-90.339324_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/38.798163,-90.559493_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/38.974446,-94.551028_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/39.014388,-94.736880_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/39.047266,-84.246780_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/39.173099,-91.886520_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/39.283537,-76.613423_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/39.392193,-119.790039_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/39.620273,-104.888916_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/39.695696,-105.071700_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/39.755896,-105.008848_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/39.855786,-104.956085_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/39.868045,-82.936566_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/39.874154,-75.262361_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/39.875982,-75.121634_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/39.914940,-105.006603_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/39.952675,-83.123390_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/39.955157,-75.171672_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/40.051826,-105.055939_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/40.127765,-75.347696_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/40.364099,-111.742177_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/40.713846,-73.999738_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/40.733206,-74.175194_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/40.739117,-73.982094_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/40.774048,-73.949068_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/40.804153,-96.682148_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/41.113269,-85.176869_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/41.846534,-87.978608_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/41.887329,-87.649553_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/41.903758,-87.628874_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/41.936000,-87.642619_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/42.436798,-96.413577_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/42.888819,-78.875887_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/44.060228,-123.065456_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/44.067844,-103.195831_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/44.977059,-93.278811_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/45.306483,-122.948029_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/45.415814,-122.593356_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/45.504331,-122.475114_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/45.831864,-109.961836_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/47.621865,-122.337855_19_600x600_approx.png', 'sxm-ecomm-sagemaker-dev/images/49.226110,-123.002441_19_600x600_approx.png']\n"
     ]
    }
   ],
   "source": [
    "fs = s3fs.S3FileSystem()\n",
    "\n",
    "# To List 5 files in your accessible bucket\n",
    "images = fs.ls('s3://sxm-ecomm-sagemaker-dev/images/')\n",
    "# images = (images[1:])\n",
    "#print(images)\n",
    "print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get coords from s3 file\n",
    "#client = boto3.client('s3')\n",
    "#path = 's3://sxm-ecommerce-p66-location-data/coords/3000_coords.csv'\n",
    "#df = pd.read_csv(path)\n",
    "#df.drop('location_id', axis=1, inplace=True)\n",
    "#df.drop('merchant_location_id', axis=1, inplace=True)\n",
    "#df.sort_values(by=['merchant_location_latitude'], inplace=True)\n",
    "#df.to_csv('sorted_csv.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('sorted_csv.csv')\n",
    "#df = df.drop(df.index[range(105)])\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_colors(uniqueColor, maxColor, minColor):    \n",
    "    for color_idx in argSortedCounts[-numColors:]:\n",
    "        color = uniqueColor[color_idx]\n",
    "        R = color[0]\n",
    "        G = color[1]\n",
    "        B = color[2]\n",
    "        maxColor = scale_max_color(maxColor, R, G, B)\n",
    "        minColor = scale_min_color(minColor, R, G, B)\n",
    "\n",
    "def scale_max_color(maxColor, R, G, B):\n",
    "    if R > maxColor[0]:\n",
    "            maxColor[0] = R\n",
    "    if G > maxColor[1]:\n",
    "            maxColor[1] = G\n",
    "    if B > maxColor[2]:\n",
    "            maxColor[2] = B\n",
    "    return maxColor\n",
    "                \n",
    "def scale_min_color(minColor, R, G, B):\n",
    "    if R < minColor[0]:\n",
    "        minColor[0] = R\n",
    "    if G < minColor[1]:\n",
    "        minColor[1] = G\n",
    "    if B < minColor[2]:\n",
    "        minColor[2] = B\n",
    "    return minColor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boost_contrast(i, minColor, maxcolor):\n",
    "    iContrast = np.zeros(i.shape)\n",
    "    iContrast = (i - minColor) * 255 / (maxColor - minColor)        \n",
    "    return iContrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    }
   ],
   "source": [
    "img_num = 0\n",
    "for image in images:\n",
    "#     image = 'sxm-ecommerce-p66-location-data/version2/training_images/30.166849_-81.748018_19_600x600_approx.png'\n",
    "\n",
    "    with fs.open(image) as f:\n",
    "        i = plt.imread(f, 0)\n",
    "        plt.imshow(i)\n",
    "        #print(i.shape)\n",
    "        flatImage = np.reshape(i, (i.shape[0]*i.shape[1], i.shape[2]))\n",
    "        \n",
    "        uniqueColor, counts = np.unique(flatImage, axis=0, return_counts=True)\n",
    "        #print(counts)\n",
    "        sortedCounts = np.sort(counts)\n",
    "        argSortedCounts = np.argsort(counts)\n",
    "        \n",
    "        kernelO = np.ones((5, 5), np.uint8)\n",
    "        \n",
    "        numColors = 4\n",
    "        maxColor = np.zeros(3)\n",
    "        minColor = np.array([255, 255, 255])\n",
    "        scale_colors(uniqueColor, maxColor, minColor)\n",
    "\n",
    "        contrast = boost_contrast(i, minColor, maxColor)\n",
    "        plt.imshow(contrast)\n",
    "        #plt.show()\n",
    "        \n",
    "        num = 0\n",
    "        for color_idx in argSortedCounts[-numColors:]:\n",
    "            #print(num)\n",
    "            num += 1\n",
    "            color = uniqueColor[color_idx]\n",
    "            \n",
    "            colorImage = i == color\n",
    "\n",
    "            stacked = np.sum(colorImage, axis=2)\n",
    "            stacked = stacked >= 3\n",
    "            stacked = np.asarray(stacked, dtype=float)\n",
    "            opened = cv2.morphologyEx(stacked, cv2.MORPH_OPEN, kernelO)\n",
    "\n",
    "            #lat_coords = df['merchant_location_latitude'].values[img_num]\n",
    "            #long_coords = df['merchant_location_longitude'].values[img_num]\n",
    "#             plt.imshow(opened)\n",
    "#             print(opened.shape)\n",
    "#             plt.title('%f, %f_Freq:%i' % (lat_coords, long_coords, num))\n",
    "#             plt.axis('off')\n",
    "#             plt.savefig('data/training_freqs/img_%f, %f_freq_%i.png' % (lat_coords, long_coords, num), bbox_inches='tight')\n",
    "            image = image.replace('sxm-ecomm-sagemaker-dev/images/', '')\n",
    "            coords_name = image.replace('_19_600x600_approx.png', '')\n",
    "            plt.imsave('data/output/freqs/img_%s_freq_%i.png' % (coords_name, num), opened)\n",
    "            #plt.show()\n",
    "    img_num +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
